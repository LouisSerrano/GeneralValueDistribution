{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, jdc, shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rl_glue import RLGlue\n",
    "from agent import BaseAgent\n",
    "from maze_env import MazeEnvironment2\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Learning agent here\n",
    "class QLearningAgent(BaseAgent):\n",
    "    def agent_init(self, agent_info):\n",
    "        \"\"\"Setup for the agent called when the experiment first starts.\n",
    "        \n",
    "        Args:\n",
    "        agent_init_info (dict), the parameters used to initialize the agent. The dictionary contains:\n",
    "        {\n",
    "            num_states (int): The number of states,\n",
    "            num_actions (int): The number of actions,\n",
    "            epsilon (float): The epsilon parameter for exploration,\n",
    "            step_size (float): The step-size,\n",
    "            discount (float): The discount factor,\n",
    "        }\n",
    "        \n",
    "        \"\"\"\n",
    "        # Store the parameters provided in agent_init_info.\n",
    "        self.num_actions =  agent_info.get(\"num_actions\", 4)\n",
    "        self.num_states =  agent_info.get(\"num_states\", 60)\n",
    "        self.epsilon =  agent_info.get(\"epsilon\", 0.1)\n",
    "        self.step_size =  agent_info.get(\"step_size\", 0.125)\n",
    "        self.discount =  agent_info.get(\"discount\", 0.95)\n",
    "        self.rand_generator = np.random.RandomState(agent_info[\"seed\"])\n",
    "        \n",
    "        # Create an array for action-value estimates and initialize it to zero.\n",
    "        self.q = np.zeros((self.num_states, self.num_actions)) # The array of action-value estimates.\n",
    "\n",
    "        \n",
    "    def agent_start(self, state):\n",
    "        \"\"\"The first method called when the episode starts, called after\n",
    "        the environment starts.\n",
    "        Args:\n",
    "            state (int): the state from the\n",
    "                environment's evn_start function.\n",
    "        Returns:\n",
    "            action (int): the first action the agent takes.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Choose action using epsilon greedy.\n",
    "        current_q = self.q[state,:]\n",
    "        if self.rand_generator.rand() < self.epsilon:\n",
    "            action = self.rand_generator.randint(self.num_actions)\n",
    "        else:\n",
    "            action = self.argmax(current_q)\n",
    "        self.prev_state = state\n",
    "        self.prev_action = action\n",
    "        return action\n",
    "    \n",
    "    def agent_step(self, reward, state):\n",
    "        \"\"\"A step taken by the agent.\n",
    "        Args:\n",
    "            reward (float): the reward received for taking the last action taken\n",
    "            state (int): the state from the\n",
    "                environment's step based on where the agent ended up after the\n",
    "                last step.\n",
    "        Returns:\n",
    "            action (int): the action the agent is taking.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Choose action using epsilon greedy.\n",
    "        current_q = self.q[state, :]\n",
    "        if self.rand_generator.rand() < self.epsilon:\n",
    "            action = self.rand_generator.randint(self.num_actions)\n",
    "        else:\n",
    "            action = self.argmax(current_q)\n",
    "        \n",
    "        self.q[self.prev_state, self.prev_action] += self.step_size*(reward +\n",
    "                                                           self.discount*max(current_q)\n",
    "                                                          - self.q[self.prev_state, self.prev_action]) \n",
    "        \n",
    "        self.prev_state = state\n",
    "        self.prev_action = action\n",
    "        return action\n",
    "    \n",
    "    def agent_end(self, reward):\n",
    "        \"\"\"Run when the agent terminates.\n",
    "        Args:\n",
    "            reward (float): the reward the agent received for entering the\n",
    "                terminal state.\n",
    "        \"\"\"\n",
    "        self.q[self.prev_state, self.prev_action] += self.step_size*(reward -\n",
    "                                                                     self.q[self.prev_state, self.prev_action])  \n",
    "        \n",
    "    def argmax(self, q_values):\n",
    "        \"\"\"argmax with random tie-breaking\n",
    "        Args:\n",
    "            q_values (Numpy array): the array of action-values\n",
    "        Returns:\n",
    "            action (int): an action with the highest value\n",
    "        \"\"\"\n",
    "        top = float(\"-inf\")\n",
    "        ties = []\n",
    "\n",
    "        for i in range(len(q_values)):\n",
    "            if q_values[i] > top:\n",
    "                top = q_values[i]\n",
    "                ties = []\n",
    "\n",
    "            if q_values[i] == top:\n",
    "                ties.append(i)\n",
    "\n",
    "        return self.rand_generator.choice(ties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## semi-gradient Q-learning with tile coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiles3 as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeTileCoder:\n",
    "    def __init__(self, num_tilings=4, num_tiles=4):\n",
    "        \"\"\"\n",
    "        Initializes the Maze Tile Coder\n",
    "        Initializers:\n",
    "        iht_size -- int, the size of the index hash table, typically a power of 2\n",
    "        num_tilings -- int, the number of tilings\n",
    "        num_tiles -- int, the number of tiles. Here both the width and height of the\n",
    "                     tile coder are the same\n",
    "        Class Variables:\n",
    "        self.iht -- tc.IHT, the index hash table that the tile coder will use\n",
    "        self.num_tilings -- int, the number of tilings the tile coder will use\n",
    "        self.num_tiles -- int, the number of tiles the tile coder will use\n",
    "        \"\"\"\n",
    "        self.iht_size = num_tilings*(num_tiles+1)*(num_tiles+1)\n",
    "        self.iht = tc.IHT(self.iht_size)\n",
    "        self.num_tilings = num_tilings\n",
    "        self.num_tiles = num_tiles\n",
    "        \n",
    "    def get_observation(self, state):\n",
    "        return state//10, state%10\n",
    "    \n",
    "    def get_tiles(self, state):\n",
    "        i_scale = self.num_tiles / 5\n",
    "        j_scale = self.num_tiles / 9 \n",
    "        \n",
    "        position_i, position_j = self.get_observation(state)\n",
    "        tiles = tc.tiles(self.iht, self.num_tilings, [(5 - position_i)*i_scale, \n",
    "                                                      position_j*j_scale])  \n",
    "        return np.array(tiles)\n",
    "    \n",
    "    def get_state_vector(self, state):\n",
    "        active_tile = self.get_tiles(state)\n",
    "        vector = np.zeros(self.iht_size)\n",
    "        vector[active_tile] = 1\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Q-Learning Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LinearQLearningAgent\n",
    "class LinearQLearningAgent(BaseAgent):\n",
    "        \n",
    "    def agent_init(self, agent_info={}):\n",
    "        \"\"\"Setup for the agent called when the experiment first starts.\"\"\"\n",
    "    \n",
    "        # Create a random number generator with the provided seed to seed the agent for reproducibility.\n",
    "        self.rand_generator = np.random.RandomState(agent_info.get(\"seed\"))\n",
    "        # Policy will be given, recall that the goal is to accurately estimate its corresponding value function. \n",
    "        self.num_actions = agent_info.get(\"num_actions\", 4)\n",
    "        # Discount factor (gamma) to use in the updates.\n",
    "        self.discount = agent_info.get(\"discount\", 0.95)\n",
    "        # The learning rate or step size parameter (alpha) to use in updates.\n",
    "        self.step_size = agent_info.get(\"step_size\", 0.1/4)\n",
    "        # epsilon\n",
    "        self.epsilon = agent_info.get(\"epsilon\", 0.1)\n",
    "        \n",
    "        # tiles\n",
    "        self.num_tilings = agent_info.get(\"num_tilings\", 4)\n",
    "        self.num_tiles = agent_info.get(\"num_tiles\", 4)\n",
    "        \n",
    "        # tile coder\n",
    "        self.tc = MazeTileCoder(num_tilings=self.num_tilings, \n",
    "                                         num_tiles=self.num_tiles)\n",
    "                # we have two features\n",
    "        self.iht_size = self.tc.iht_size\n",
    "        self.weights = np.ones((self.num_actions, self.iht_size)) * 0\n",
    "\n",
    "        # stores all possible features\n",
    "        # self.all_state_features = np.array([[i/6, j/10] for i in range(6) for j in range(10)])\n",
    "\n",
    "\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "        \n",
    "    def select_action(self, tiles):\n",
    "        \"\"\"\n",
    "        Selects an action using epsilon greedy\n",
    "        Args:\n",
    "        tiles - np.array, an array of active tiles\n",
    "        Returns:\n",
    "        (chosen_action, action_value) - (int, float), tuple of the chosen action\n",
    "                                        and it's value\n",
    "        \"\"\"\n",
    "        action_values = []\n",
    "        chosen_action = None\n",
    "        \n",
    "        # First loop through the weights of each action and populate action_values\n",
    "        # with the action value for each action and tiles instance\n",
    "        \n",
    "        # Use np.random.random to decide if an exploritory action should be taken\n",
    "        # and set chosen_action to a random action if it is\n",
    "        # Otherwise choose the greedy action using the given argmax \n",
    "        # function and the action values (don't use numpy's armax)\n",
    "        \n",
    "        for action in range(self.num_actions):\n",
    "            action_values.append(np.sum(self.weights[action][tiles]))\n",
    "        if np.random.random() < self.epsilon:\n",
    "            chosen_action =  np.random.randint(self.num_actions)\n",
    "        else:\n",
    "            chosen_action = self.argmax(action_values)\n",
    "        \n",
    "        return chosen_action, action_values[chosen_action]\n",
    "    \n",
    "    def agent_start(self, state):\n",
    "        \"\"\"The first method called when the experiment starts, called after\n",
    "        the environment starts.\n",
    "        Args:\n",
    "            state (Numpy array): the state from the\n",
    "                environment's evn_start function.\n",
    "        Returns:\n",
    "            self.last_action [int] : The first action the agent takes.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.last_state = state\n",
    "        current_i = state//10\n",
    "        current_j = state%10\n",
    "        \n",
    "        active_tiles = self.tc.get_tiles(state)\n",
    "        current_action, current_value = self.select_action(active_tiles)\n",
    "        \n",
    "        self.last_action = current_action\n",
    "        self.previous_tiles = np.copy(active_tiles)\n",
    "\n",
    "        return self.last_action\n",
    "\n",
    "    def agent_step(self, reward, state):\n",
    "        \"\"\"A step taken by the agent.\n",
    "        Args:\n",
    "            reward [float]: the reward received for taking the last action taken\n",
    "            state [int]: the state from the environment's step, where the agent ended up after the last step\n",
    "        Returns:\n",
    "            self.last_action [int] : The action the agent is taking.\n",
    "        \"\"\"\n",
    "        \n",
    "        # get relevant feature\n",
    "        current_i = state//10\n",
    "        current_j = state%10\n",
    "        # select action\n",
    "        active_tiles = self.tc.get_tiles(state)\n",
    "        current_action, current_value = self.select_action(active_tiles)\n",
    "        \n",
    "        self.weights[self.last_action][self.previous_tiles] += self.step_size*(reward + current_value*self.discount - np.sum(self.weights[self.last_action][self.previous_tiles]))\n",
    "\n",
    "        self.last_state = state\n",
    "        self.last_action = current_action\n",
    "        self.previous_tiles = active_tiles\n",
    "        \n",
    "        return self.last_action\n",
    "\n",
    "    def agent_end(self, reward):\n",
    "        \"\"\"Run when the agent terminates.\n",
    "        Args:\n",
    "            reward (float): the reward the agent received for entering the\n",
    "                terminal state.\n",
    "        \"\"\"\n",
    "        self.weights[self.last_action][self.previous_tiles] += self.step_size *(reward - np.sum(self.weights[self.last_action][self.previous_tiles]))\n",
    "\n",
    "        return\n",
    "        \n",
    "    def agent_message(self, message):\n",
    "        # We will implement this method later\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def argmax(self, q_values):\n",
    "        \"\"\"argmax with random tie-breaking\n",
    "        Args:\n",
    "            q_values (Numpy array): the array of action-values\n",
    "        Returns:\n",
    "            action (int): an action with the highest value\n",
    "        \"\"\"\n",
    "        top = float(\"-inf\")\n",
    "        ties = []\n",
    "\n",
    "        for i in range(len(q_values)):\n",
    "            if q_values[i] > top:\n",
    "                top = q_values[i]\n",
    "                ties = []\n",
    "\n",
    "            if q_values[i] == top:\n",
    "                ties.append(i)\n",
    "\n",
    "        return self.rand_generator.choice(ties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MazeEnvironment2\n",
    "agents = {\n",
    "    \"Q-learning\": QLearningAgent,\n",
    "    \"Linear-Q-learning\": LinearQLearningAgent\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reward_sums = {} # Contains sum of rewards during episode\n",
    "all_state_visits = {} # Contains state visit counts during the last 10 episodes\n",
    "agent_info = {\"num_actions\": 4, \"num_states\": 60, \"epsilon\": 0.01, \"step_size\": 0.1, \"discount\": 0.95}\n",
    "env_info = {}\n",
    "num_runs = 100 # The number of runs\n",
    "num_episodes = 500 # The number of episodes in each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/louisserrano/Documents/Oxford/Courses/Trinity/Dissertation/Code/Background/RL/Policy_Iteration/Maze/results.zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm = \"Q-learning\"\n",
    "all_reward_sums[algorithm] = []\n",
    "all_state_visits[algorithm] = []\n",
    "for run in tqdm(range(num_runs)):\n",
    "    agent_info[\"seed\"] = run\n",
    "    rl_glue = RLGlue(env, agents[algorithm])\n",
    "    rl_glue.rl_init(agent_info, env_info)\n",
    "\n",
    "    reward_sums = []\n",
    "    state_visits = np.zeros(60)\n",
    "#         last_episode_total_reward = 0\n",
    "    for episode in range(num_episodes):\n",
    "        if episode < num_episodes - 10:\n",
    "            # Runs an episode\n",
    "            rl_glue.rl_episode(0) \n",
    "        else: \n",
    "            # Runs an episode while keeping track of visited states\n",
    "            state, action = rl_glue.rl_start()\n",
    "            state_visits[state] += 1\n",
    "            is_terminal = False\n",
    "            while not is_terminal:\n",
    "                reward, state, action, is_terminal = rl_glue.rl_step()\n",
    "                state_visits[state] += 1\n",
    "\n",
    "        reward_sums.append(rl_glue.rl_return())\n",
    "#             last_episode_total_reward = rl_glue.rl_return()\n",
    "\n",
    "    all_reward_sums[algorithm].append(reward_sums)\n",
    "    \n",
    "    all_state_visits[algorithm].append(state_visits)\n",
    "\n",
    "# save results\n",
    "import os\n",
    "import shutil\n",
    "os.makedirs('results', exist_ok=True)\n",
    "np.save('results/q_learning.npy', all_reward_sums['Q-learning'])\n",
    "shutil.make_archive('results', 'zip', '.', 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do not modify this cell!\n",
    "for algorithm, position in [(\"Q-learning\", 211)]:\n",
    "    plt.subplot(position)\n",
    "    average_state_visits = np.array(all_state_visits[algorithm]).mean(axis=0)\n",
    "    grid_state_visits = average_state_visits.reshape((6,10))\n",
    "    \n",
    "    # gray the obstacles\n",
    "    obstacles = [[2,1],[3,1],[4,1],[0,4],[1,4],[5,5],[1,7],[2,7],[2,8],[3,8]]\n",
    "    for (i,j) in obstacles:\n",
    "        grid_state_visits[i,j] = np.nan\n",
    "    \n",
    "    plt.pcolormesh(grid_state_visits, edgecolors='gray', linewidth=2)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(algorithm)\n",
    "    plt.axis('off')\n",
    "    cm = plt.get_cmap()\n",
    "    cm.set_bad('black')\n",
    "\n",
    "    plt.subplots_adjust(bottom=-1, right= 0.9, top=1)\n",
    "    cax = plt.axes([1, 0.1, 0.075, 0.9])\n",
    "cbar = plt.colorbar(cax=cax)\n",
    "#cbar.ax.set_ylabel(\"Visits during\\n the last 10\\n episodes\", rotation=0, labelpad=70)\n",
    "plt.savefig('results/qlearning_visits.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reward_sums = {} # Contains sum of rewards during episode\n",
    "all_state_visits = {} # Contains state visit counts during the last 10 episodes\n",
    "agent_info = {\"num_actions\": 4, \"num_states\": 60, \"epsilon\": 0.01, \"step_size\": 0.1/4, \"discount\": 0.95,\n",
    "             \"num_tiles\": 7}\n",
    "env_info = {}\n",
    "num_runs = 100 # The number of runs\n",
    "num_episodes = 500 # The number of episodes in each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:01<02:59,  1.81s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:02<02:38,  1.61s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:04<02:26,  1.51s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:05<02:19,  1.46s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:06<02:09,  1.36s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:07<02:04,  1.32s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:09<02:00,  1.30s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:10<01:57,  1.28s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:11<01:54,  1.26s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:12<01:51,  1.24s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:14<02:05,  1.41s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:16<02:14,  1.53s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:17<02:06,  1.45s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:19<02:03,  1.43s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:20<01:56,  1.37s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:21<01:51,  1.33s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:22<01:48,  1.31s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:24<01:45,  1.29s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:25<01:37,  1.21s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:26<01:34,  1.19s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:27<01:38,  1.25s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:28<01:40,  1.29s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:30<01:40,  1.31s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:31<01:36,  1.27s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:32<01:32,  1.24s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:33<01:32,  1.25s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:35<01:30,  1.24s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:36<01:31,  1.26s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:37<01:26,  1.22s/it]\u001b[A\n",
      " 30%|███       | 30/100 [00:38<01:26,  1.24s/it]\u001b[A\n",
      " 31%|███       | 31/100 [00:40<01:26,  1.25s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:41<01:25,  1.26s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:42<01:26,  1.29s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:44<01:40,  1.52s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:46<01:36,  1.49s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:47<01:34,  1.47s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:49<01:29,  1.42s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:50<01:28,  1.42s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:51<01:26,  1.42s/it]\u001b[A\n",
      " 40%|████      | 40/100 [00:53<01:21,  1.35s/it]\u001b[A\n",
      " 41%|████      | 41/100 [00:54<01:18,  1.34s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:55<01:17,  1.33s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:57<01:17,  1.36s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:58<01:15,  1.36s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:59<01:15,  1.37s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:01<01:16,  1.41s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:02<01:14,  1.40s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:03<01:08,  1.31s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:05<01:05,  1.28s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:06<01:05,  1.31s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:07<01:02,  1.27s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:08<01:01,  1.27s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:10<00:59,  1.26s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:11<00:58,  1.27s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:12<00:56,  1.26s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:13<00:56,  1.28s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [01:15<00:53,  1.25s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [01:16<00:53,  1.27s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [01:17<00:49,  1.22s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [01:18<00:50,  1.26s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [01:20<00:47,  1.23s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [01:21<00:47,  1.24s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [01:22<00:44,  1.21s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [01:23<00:44,  1.23s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [01:24<00:42,  1.20s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [01:26<00:40,  1.19s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [01:27<00:38,  1.17s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [01:28<00:37,  1.17s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [01:29<00:34,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [01:30<00:34,  1.17s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [01:31<00:34,  1.20s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [01:33<00:33,  1.21s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [01:34<00:33,  1.24s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [01:35<00:31,  1.21s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [01:36<00:30,  1.20s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [01:38<00:29,  1.23s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [01:39<00:31,  1.38s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [01:41<00:34,  1.59s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [01:43<00:31,  1.51s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [01:44<00:29,  1.46s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [01:45<00:26,  1.39s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [01:46<00:24,  1.33s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [01:48<00:23,  1.37s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [01:50<00:23,  1.44s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [01:51<00:21,  1.41s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [01:52<00:19,  1.37s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [01:53<00:17,  1.35s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [01:55<00:16,  1.36s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [01:56<00:15,  1.37s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [01:58<00:13,  1.36s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [01:59<00:12,  1.36s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [02:00<00:11,  1.41s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [02:02<00:09,  1.38s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [02:03<00:08,  1.38s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [02:04<00:06,  1.36s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [02:06<00:05,  1.43s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [02:07<00:04,  1.38s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [02:09<00:02,  1.42s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [02:11<00:01,  1.58s/it]\u001b[A\n",
      "100%|██████████| 100/100 [02:12<00:00,  1.33s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/louisserrano/Documents/Oxford/Courses/Trinity/Dissertation/Code/Background/RL/Policy_Iteration/Maze/results.zip'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm = \"Linear-Q-learning\"\n",
    "all_reward_sums[algorithm] = []\n",
    "all_state_visits[algorithm] = []\n",
    "for run in tqdm(range(num_runs)):\n",
    "    agent_info[\"seed\"] = run\n",
    "    rl_glue = RLGlue(env, agents[algorithm])\n",
    "    rl_glue.rl_init(agent_info, env_info)\n",
    "\n",
    "    reward_sums = []\n",
    "    state_visits = np.zeros(60)\n",
    "#         last_episode_total_reward = 0\n",
    "    for episode in range(num_episodes):\n",
    "        if episode < num_episodes - 10:\n",
    "            # Runs an episode\n",
    "            rl_glue.rl_episode(0) \n",
    "        else: \n",
    "            # Runs an episode while keeping track of visited states\n",
    "            state, action = rl_glue.rl_start()\n",
    "            state_visits[state] += 1\n",
    "            is_terminal = False\n",
    "            while not is_terminal:\n",
    "                reward, state, action, is_terminal = rl_glue.rl_step()\n",
    "                state_visits[state] += 1\n",
    "\n",
    "        reward_sums.append(rl_glue.rl_return())\n",
    "#             last_episode_total_reward = rl_glue.rl_return()\n",
    "\n",
    "    all_reward_sums[algorithm].append(reward_sums)\n",
    "    all_state_visits[algorithm].append(state_visits)\n",
    "\n",
    "# save results\n",
    "import os\n",
    "import shutil\n",
    "os.makedirs('results', exist_ok=True)\n",
    "np.save('results/q_learning.npy', all_reward_sums[\"Linear-Q-learning\"])\n",
    "#np.save('results/expected_sarsa.npy', all_reward_sums['Expected Sarsa'])\n",
    "shutil.make_archive('results', 'zip', '.', 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do not modify this cell!\n",
    "for algorithm, position in [(\"Linear-Q-learning\", 211)]:\n",
    "    plt.subplot(position)\n",
    "    average_state_visits = np.array(all_state_visits[algorithm]).mean(axis=0)\n",
    "    grid_state_visits = average_state_visits.reshape((6,10))\n",
    "    \n",
    "    # gray the obstacles\n",
    "    obstacles = [[2,1],[3,1],[4,1],[0,4],[1,4],[5,5],[1,7],[2,7],[2,8],[3,8]]\n",
    "    for (i,j) in obstacles:\n",
    "        grid_state_visits[i,j] = np.nan\n",
    "    \n",
    "    plt.pcolormesh(grid_state_visits, edgecolors='gray', linewidth=2)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(algorithm)\n",
    "    plt.axis('off')\n",
    "    cm = plt.get_cmap()\n",
    "    cm.set_bad('black')\n",
    "\n",
    "    plt.subplots_adjust(bottom=-1, right= 0.9, top=1)\n",
    "    cax = plt.axes([1, 0.1, 0.075, 0.9])\n",
    "cbar = plt.colorbar(cax=cax)\n",
    "#cbar.ax.set_ylabel(\"Visits during\\n the last 10\\n episodes\", rotation=0, labelpad=70)\n",
    "plt.savefig('results/linearqlearning_visits.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "RUN: 5\n",
      "RUN: 10\n",
      "RUN: 15\n",
      "RUN: 20\n",
      "RUN: 25\n",
      "RUN: 30\n",
      "RUN: 35\n",
      "RUN: 40\n",
      "RUN: 45\n",
      "RUN: 50\n",
      "RUN: 55\n",
      "RUN: 60\n",
      "RUN: 65\n",
      "RUN: 70\n",
      "RUN: 75\n",
      "RUN: 80\n",
      "RUN: 85\n",
      "RUN: 90\n",
      "RUN: 95\n",
      "RUN: 0\n",
      "RUN: 5\n",
      "RUN: 10\n",
      "RUN: 15\n",
      "RUN: 20\n",
      "RUN: 25\n",
      "RUN: 30\n",
      "RUN: 35\n",
      "RUN: 40\n",
      "RUN: 45\n",
      "RUN: 50\n",
      "RUN: 55\n",
      "RUN: 60\n",
      "RUN: 65\n",
      "RUN: 70\n",
      "RUN: 75\n",
      "RUN: 80\n",
      "RUN: 85\n",
      "RUN: 90\n",
      "RUN: 95\n"
     ]
    }
   ],
   "source": [
    "num_runs = 100\n",
    "num_episodes = 50\n",
    "env_info = {}\n",
    "agent_info = {\"num_tiles\": 4, \"num_tilings\": 4, \"epsilon\" : 0.01, \"step_size\" : 0.1}\n",
    "all_steps = {}\n",
    "for algorithm in ['Q-learning', 'Linear-Q-learning']:\n",
    "    if algorithm == 'Linear-Q-learning':\n",
    "        agent_info.update({\"step_size\": 0.1/4})\n",
    "    agent = agents[algorithm]\n",
    "    env = MazeEnvironment2\n",
    "    steps = []\n",
    "    for run in range(num_runs):\n",
    "        agent_info[\"seed\"] = run\n",
    "        if run % 5 == 0:\n",
    "            print(\"RUN: {}\".format(run))\n",
    "\n",
    "        rl_glue = RLGlue(env, agent)\n",
    "        rl_glue.rl_init(agent_info, env_info)\n",
    "        steps_per_episode = []\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            rl_glue.rl_episode(15000)\n",
    "            steps_per_episode.append(rl_glue.num_steps)\n",
    "\n",
    "        steps.append(np.array(steps_per_episode))\n",
    "    all_steps[algorithm] = steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for algorithm in ['Q-learning', 'Linear-Q-learning']:\n",
    "    plt.plot(np.mean(np.array(all_steps[algorithm]), axis=0), label = algorithm)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Steps per episode averaged over different runs\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.savefig(\"results/steps_per_episode.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
